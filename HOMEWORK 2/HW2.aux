\relax 
\citation{GMM_EM}
\citation{GMM_EM}
\@writefile{toc}{\contentsline {section}{\numberline {I}INTRODUCTION}{1}}
\newlabel{sec:Intro}{{I}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Theory}{1}}
\newlabel{sec:Theory}{{II}{1}}
\newlabel{eq:loglikelihood}{{1}{1}}
\newlabel{eq:new_parameters1}{{2a}{1}}
\newlabel{eq:new_parameters2}{{2b}{1}}
\newlabel{eq:new_parameters3}{{2c}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-A}Expectation Maximization}{1}}
\newlabel{sec:TheoryExpectationMaximization}{{II-A}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-B}Gaussian Mixture Models}{2}}
\newlabel{sec:TheoryGMM}{{II-B}{2}}
\newlabel{eq:GMMEq}{{3}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-C}K-means}{2}}
\newlabel{sec:TheoryKmeans}{{II-C}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Experiments}{2}}
\newlabel{sec:Experiments}{{III}{2}}
\newlabel{eq:means}{{4}{2}}
\newlabel{eq:CVMatrices}{{5}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}EM Algorithm}{2}}
\newlabel{sec:Experiment_EM_Algorithm}{{III-A}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Generated data with the parameter specification of Eq. 4\hbox {}, and Eq. 5\hbox {}. The blue group corresponds to $\mu _{1}$, $\Sigma _{1}$, the red group corresponds to $\mu _{2}$, $\Sigma _{2}$, and the green group corresponds to $\mu _{3}$, $\Sigma _{3}$.}}{2}}
\newlabel{fig:data}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Representation of the Data Likelihood}{2}}
\newlabel{sec:Experiment_Representation_Data_Likelihood}{{III-B}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Unsupervised Classification}{2}}
\newlabel{sec:Experiment_Unsupervised_Classification}{{III-C}{2}}
\newlabel{fig:GMMIteration1}{{2(a)}{3}}
\newlabel{sub@fig:GMMIteration1}{{(a)}{3}}
\newlabel{fig:GMMIteration7}{{2(b)}{3}}
\newlabel{sub@fig:GMMIteration7}{{(b)}{3}}
\newlabel{fig:GMMIteration14}{{2(c)}{3}}
\newlabel{sub@fig:GMMIteration14}{{(c)}{3}}
\newlabel{fig:GMMIteration20}{{2(d)}{3}}
\newlabel{sub@fig:GMMIteration20}{{(d)}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Evolution of the Expectation Maximization algorithm using Gaussian mixture models at iterations (a) $1$, (b) $7$, (c) $14$, and (d) $20$. }}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Scatter plot. The bigger the balls are, the higher the probability value the samples have assigned to them.}}{3}}
\newlabel{fig:ScatterPlot}{{3}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Classification scheme. In this case, $\epsilon _{blue} = 0.004$, $\epsilon _{red} = 0.012$, and $\epsilon _{green} = 0.006$}}{3}}
\newlabel{fig:LevelsClassificationInsight}{{4}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-D}Comparison to the K-means Algorithm}{3}}
\newlabel{sec:Experiment_Comparison_Kmeans_Algorithm}{{III-D}{3}}
\newlabel{sec:Experiment_Mahalanobis_distance}{{III-D.1}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {III-D.1}Mahalanobis distance}{3}}
\newlabel{sec:Experiment_Kmeans_procedure}{{III-D.2}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {III-D.2}K-means procedure and Parameter update}{3}}
\newlabel{fig:KMeansIteration1}{{5(a)}{4}}
\newlabel{sub@fig:KMeansIteration1}{{(a)}{4}}
\newlabel{fig:KMeansIteration23}{{5(b)}{4}}
\newlabel{sub@fig:KMeansIteration23}{{(b)}{4}}
\newlabel{fig:KMeansIteration38}{{5(c)}{4}}
\newlabel{sub@fig:KMeansIteration38}{{(c)}{4}}
\newlabel{fig:KMeansIteration53}{{5(d)}{4}}
\newlabel{sub@fig:KMeansIteration53}{{(d)}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Output of \emph  {svmtrain} with different values of $\sigma $. (a), $\sigma = 0.05$. (b), $\sigma = 1$. (c), $\sigma = 1.4$.}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{4}}
\newlabel{sec:Experiment_growing_pruning_10}{{III-D.3}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {III-D.3}Parameter initialization, growing-pruning and use in an 10 dimensional problem}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusion}{4}}
\newlabel{sec:Conclusion}{{IV}{4}}
\bibstyle{IEEEtran}
\bibdata{References}
\bibcite{GMM_EM}{1}
\newlabel{fig:ui_Paths_GMM}{{6(a)}{5}}
\newlabel{sub@fig:ui_Paths_GMM}{{(a)}{5}}
\newlabel{fig:ui_Paths_K_MEANS}{{6(b)}{5}}
\newlabel{sub@fig:ui_Paths_K_MEANS}{{(b)}{5}}
\newlabel{fig:EvolutionMuDisplacement_GMM}{{6(c)}{5}}
\newlabel{sub@fig:EvolutionMuDisplacement_GMM}{{(c)}{5}}
\newlabel{fig:EvolutionMuDisplacement_K_MEANS}{{6(d)}{5}}
\newlabel{sub@fig:EvolutionMuDisplacement_K_MEANS}{{(d)}{5}}
\newlabel{fig:loglikelihookGMMTheOne}{{6(e)}{5}}
\newlabel{sub@fig:loglikelihookGMMTheOne}{{(e)}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Comparison between Expectation Maximization with Gaussian mixture models and k-means. (a) Trajectory of the means, and (c) displacement of means for Expectation Maximization with Gaussian mixture models. (b) Trajectory of the means,, and (e) displacement of means for k-means. (e) Log-likelihood for Expectation Maximization with Gaussian mixture models}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {}}}{5}}
\@writefile{toc}{\contentsline {section}{References}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Selection of initial means. }}{6}}
\newlabel{fig:ProbabilityAssigment}{{7}{6}}
